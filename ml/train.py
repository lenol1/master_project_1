# train.py
import pandas as pd
import numpy as np
import joblib
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from datasets import Dataset
from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer
import config

# --- 1. –§—É–Ω–∫—Ü—ñ—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –æ—á–∏—â–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö ---
def load_and_clean_data(file_path):
    print(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ {file_path}...")
    df = pd.read_csv(
        file_path, encoding='utf-8-sig', sep=',',
        engine='python', on_bad_lines='skip'
    )
    # –û—á–∏—Å—Ç–∫–∞ category_id
    df['category_id'] = (
        df['category_id'].astype(str).str.strip()
        .replace('', pd.NA)
    )
    df['category_id'] = pd.to_numeric(df['category_id'], errors='coerce')
    df = df.dropna(subset=['category_id'])
    df['category_id'] = df['category_id'].astype(int)
    # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç—É
    df['text_features'] = df['text_features'].fillna('').astype(str)
    # –ü–µ—Ä–µ–π–º–µ–Ω—É–≤–∞–Ω–Ω—è –¥–ª—è BERT
    df = df.rename(columns={'category_id': 'labels'})
    print(f"‚úÖ –î–∞–Ω—ñ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ, {len(df)} —Ä—è–¥–∫—ñ–≤.")
    return df

# --- 2. –§—É–Ω–∫—Ü—ñ—è –Ω–∞–≤—á–∞–Ω–Ω—è SKlearn ---
def train_sklearn(df):
    print("--- üöÄ –ü–æ—á–∞—Ç–æ–∫ –Ω–∞–≤—á–∞–Ω–Ω—è SKLEARN (Random Forest) ---")
    
    # –î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É –º–∏ —Ç—Ä–µ–Ω—É—î–º–æ –Ω–∞ –í–°–Ü–• –¥–∞–Ω–∏—Ö
    X_train = df['text_features']
    y_train = df['labels']

    pipeline_rf = Pipeline([
        ('tfidf', TfidfVectorizer()),
        ('model', RandomForestClassifier(random_state=42, n_jobs=-1)) # n_jobs=-1 (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –≤—Å—ñ —è–¥—Ä–∞)
    ])
    
    print("üîÑ –ù–∞–≤—á–∞–Ω–Ω—è...")
    pipeline_rf.fit(X_train, y_train)
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∫–æ–Ω–≤–µ—î—Ä —É —Ñ–∞–π–ª
    joblib.dump(pipeline_rf, config.SKLEARN_MODEL_PATH)
    print(f"‚úÖ –ú–æ–¥–µ–ª—å SKlearn –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É: {config.SKLEARN_MODEL_PATH}")

# --- 3. –§—É–Ω–∫—Ü—ñ—è –Ω–∞–≤—á–∞–Ω–Ω—è BERT ---
def train_bert(df):
    print("--- üöÄ –ü–æ—á–∞—Ç–æ–∫ –Ω–∞–≤—á–∞–Ω–Ω—è BERT ---")
    NUM_LABELS = df['labels'].nunique()

    # –ú–∏ –≤—Å–µ –æ–¥–Ω–æ —Ä–æ–∑–¥—ñ–ª–∏–º–æ, —â–æ–± –º–∞—Ç–∏ –≤–∞–ª—ñ–¥–∞—Ü—ñ—é –ø—ñ–¥ —á–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è
    df_train, df_test = train_test_split(
        df, test_size=0.1, random_state=42, stratify=df['labels']
    )
    train_dataset = Dataset.from_pandas(df_train)
    test_dataset = Dataset.from_pandas(df_test)

    tokenizer = BertTokenizer.from_pretrained(config.BERT_BASE_MODEL)
    def tokenize_function(examples):
        return tokenizer(
            examples['text_features'], padding="max_length", truncation=True, max_length=64
        )
    
    train_dataset_tokenized = train_dataset.map(tokenize_function, batched=True)
    test_dataset_tokenized = test_dataset.map(tokenize_function, batched=True)

    model = BertForSequenceClassification.from_pretrained(config.BERT_BASE_MODEL, num_labels=NUM_LABELS)

    training_args = TrainingArguments(
        output_dir='./results_temp', # –¢–∏–º—á–∞—Å–æ–≤–∞ –ø–∞–ø–∫–∞
        num_train_epochs=3,
        per_device_train_batch_size=8,
        logging_steps=50,
    )
    
    trainer = Trainer(
        model=model, args=training_args,
        train_dataset=train_dataset_tokenized,
        eval_dataset=test_dataset_tokenized,
    )
    
    print("üîÑ –ù–∞–≤—á–∞–Ω–Ω—è BERT...")
    trainer.train()
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ñ—ñ–Ω–∞–ª—å–Ω—É –º–æ–¥–µ–ª—å —Ç–∞ —Ç–æ–∫–µ–Ω—ñ–∑–µ—Ä
    trainer.save_model(config.BERT_MODEL_PATH)
    tokenizer.save_pretrained(config.BERT_MODEL_PATH)
    print(f"‚úÖ –ú–æ–¥–µ–ª—å BERT –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É: {config.BERT_MODEL_PATH}")

# --- 4. –ì–æ–ª–æ–≤–Ω–∏–π –±–ª–æ–∫ ---
if __name__ == "__main__":
    df = load_and_clean_data(config.DATA_FILE)
    
    if config.MODEL_TYPE == "BERT":
        train_bert(df)
    elif config.MODEL_TYPE == "RF":
        train_sklearn(df)
    else:
        print(f"‚ùå –ù–µ–≤—ñ–¥–æ–º–∏–π MODEL_TYPE —É config.py: {config.MODEL_TYPE}")